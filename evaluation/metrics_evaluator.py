"""
evaluation/metrics_evaluator.py

–°—á–∏—Ç–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ NER –Ω–∞ —Ä–∞–∑–º–µ—á–µ–Ω–Ω–æ–º gold dataset.

–û–∂–∏–¥–∞–µ–º—ã–µ —Ñ–∞–π–ª—ã:
 - evaluation/gold/gold_dataset.json (—Ä—É—á–Ω–∞—è —Ä–∞–∑–º–µ—Ç–∫–∞, manually_verified=true)
 - results_hybrid_final.json (–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞; –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —ç—Ç–∏ –∂–µ article_id)

–ó–∞–ø—É—Å–∫:
    python3 evaluation/metrics_evaluator.py

–í—ã–≤–æ–¥:
 - —Ç–∞–±–ª–∏—Ü–∞ precision/recall/F1
 - evaluation/reports/metrics_report.json
"""

from __future__ import annotations

import json
import re
from collections import defaultdict
from pathlib import Path
from typing import Any, Dict, List, Set, Tuple


def project_root() -> Path:
    return Path(__file__).resolve().parents[1]


class NERMetricsEvaluator:
    def __init__(self) -> None:
        self.counts: Dict[str, Dict[str, int]] = defaultdict(lambda: {"tp": 0, "fp": 0, "fn": 0})
        self.errors: List[Dict[str, Any]] = []

    @staticmethod
    def normalize(text: str) -> str:
        if not text:
            return ""
        text = text.lower().strip()
        text = re.sub(r"[^\w\s]", "", text, flags=re.UNICODE)
        text = re.sub(r"\s+", " ", text).strip()
        return text

    def extract_names(self, entities: List[Any]) -> Set[str]:
        names: Set[str] = set()
        for e in entities or []:
            if isinstance(e, str):
                raw = e
            elif isinstance(e, dict):
                raw = e.get("name") or e.get("text") or ""
            elif hasattr(e, "name"):
                raw = getattr(e, "name")
            else:
                raw = str(e)

            norm = self.normalize(str(raw))
            if norm and len(norm) > 1:
                names.add(norm)
        return names

    @staticmethod
    def _surname(word: str) -> str:
        parts = word.split()
        return parts[-1] if parts else ""

    def match_sets(self, pred: Set[str], gold: Set[str]) -> Tuple[Set[str], Set[str], Set[str]]:
        """
        –ü—Ä–æ—Å—Ç–æ–µ ¬´fuzzy¬ª —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ:
        - —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        - –≤–∫–ª—é—á–µ–Ω–∏–µ (–æ–¥–Ω–∞ —Å—Ç—Ä–æ–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç—Å—è –≤ –¥—Ä—É–≥–æ–π)
        - —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ —Ñ–∞–º–∏–ª–∏–∏ (–ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å–ª–æ–≤–æ), –µ—Å–ª–∏ —Ñ–∞–º–∏–ª–∏—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª–∏–Ω–Ω–∞—è
        """
        tp: Set[str] = set()
        matched_gold: Set[str] = set()

        for p in pred:
            for g in gold:
                if g in matched_gold:
                    continue
                if p == g or (p and g and (p in g or g in p)):
                    tp.add(p)
                    matched_gold.add(g)
                    break
                sp, sg = self._surname(p), self._surname(g)
                if sp and sg and sp == sg and len(sp) >= 4:
                    tp.add(p)
                    matched_gold.add(g)
                    break

        fp = pred - tp
        fn = gold - matched_gold
        return tp, fp, fn

    def add_article(self, article_id: str, predicted: Dict[str, Any], gold: Dict[str, Any]) -> None:
        entity_types = ["persons", "organizations", "locations"]
        for et in entity_types:
            pred_set = self.extract_names(predicted.get(et, []))
            gold_set = self.extract_names(gold.get(et, []))

            tp, fp, fn = self.match_sets(pred_set, gold_set)

            key = et.rstrip("s")  # persons->person
            self.counts[key]["tp"] += len(tp)
            self.counts[key]["fp"] += len(fp)
            self.counts[key]["fn"] += len(fn)

            self.counts["overall"]["tp"] += len(tp)
            self.counts["overall"]["fp"] += len(fp)
            self.counts["overall"]["fn"] += len(fn)

            if fp or fn:
                self.errors.append(
                    {
                        "article_id": article_id,
                        "entity_type": et,
                        "false_positives": sorted(fp),
                        "false_negatives": sorted(fn),
                    }
                )

    def metrics(self) -> Dict[str, Dict[str, float]]:
        out: Dict[str, Dict[str, float]] = {}
        for k, c in self.counts.items():
            tp, fp, fn = c["tp"], c["fp"], c["fn"]
            precision = tp / (tp + fp) if (tp + fp) else 0.0
            recall = tp / (tp + fn) if (tp + fn) else 0.0
            f1 = (2 * precision * recall / (precision + recall)) if (precision + recall) else 0.0
            out[k] = {
                "precision": round(precision, 4),
                "recall": round(recall, 4),
                "f1": round(f1, 4),
                "tp": tp,
                "fp": fp,
                "fn": fn,
                "support": tp + fn,
            }
        return out


def load_gold(path: Path) -> List[Dict[str, Any]]:
    return json.loads(path.read_text(encoding="utf-8"))


def load_predictions(path: Path) -> Dict[str, Dict[str, Any]]:
    """
    –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–∞–π–ø–ª–∞–π–Ω–∞ –ø–æ article_id.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º —Ñ–æ—Ä–º–∞—Ç —Ç–µ–∫—É—â–µ–≥–æ results_hybrid_final.json (list of dict).
    """
    data = json.loads(path.read_text(encoding="utf-8"))
    indexed: Dict[str, Dict[str, Any]] = {}
    for item in data:
        aid = str(item.get("article_id") or item.get("id") or "")
        if not aid:
            continue
        indexed[aid] = item.get("entities", {}) or {}
    return indexed


def print_table(m: Dict[str, Dict[str, float]]) -> None:
    def row(name: str) -> str:
        x = m.get(name, {})
        return f"{name:<15} {x.get('precision',0):>11.1%} {x.get('recall',0):>11.1%} {x.get('f1',0):>11.1%} {int(x.get('support',0)):>10}"

    print("\n" + "=" * 70)
    print("üìä NER METRICS REPORT")
    print("=" * 70)
    print(f"{'Entity Type':<15} {'Precision':>12} {'Recall':>12} {'F1':>12} {'Support':>10}")
    print("-" * 70)
    print(row("person"))
    print(row("organization"))
    print(row("location"))
    print("-" * 70)
    print(row("overall"))
    print("=" * 70)


def main() -> None:
    root = project_root()
    gold_path = root / "evaluation" / "gold" / "gold_dataset.json"
    # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å—á–∏—Ç–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –ø–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º, –ø–æ–ª—É—á–µ–Ω–Ω—ã–º –Ω–∞ gold-—Å—Ç–∞—Ç—å—è—Ö
    pred_path = root / "evaluation" / "reports" / "predictions_on_gold.json"
    report_path = root / "evaluation" / "reports" / "metrics_report.json"

    if not gold_path.exists():
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω gold dataset:", gold_path)
        print("   –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ: python3 evaluation/create_gold_dataset.py")
        return

    if not pred_path.exists():
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω —Ñ–∞–π–ª –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π:", pred_path)
        print("   –°–Ω–∞—á–∞–ª–∞ –ø–æ–ª—É—á–∏—Ç–µ results_hybrid_final.json (–ø–∞–π–ø–ª–∞–π–Ω).")
        return

    gold = load_gold(gold_path)
    verified = [a for a in gold if a.get("manually_verified") is True]
    if not verified:
        print("‚ö†Ô∏è –í gold dataset –Ω–µ—Ç —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π (manually_verified=true).")
        print("   –û—Ç–∫—Ä–æ–π—Ç–µ evaluation/gold/gold_dataset.json –∏ –∑–∞–ø–æ–ª–Ω–∏—Ç–µ gold_entities.")
        return

    preds = load_predictions(pred_path)

    ev = NERMetricsEvaluator()
    evaluated = 0
    missing = 0

    for a in verified:
        aid = str(a.get("article_id", ""))
        if not aid or aid not in preds:
            missing += 1
            continue
        ev.add_article(aid, preds[aid], a.get("gold_entities", {}) or {})
        evaluated += 1

    m = ev.metrics()
    print_table(m)

    report = {
        "evaluated_articles": evaluated,
        "missing_in_predictions": missing,
        "metrics": m,
        "errors_sample": ev.errors[:50],
    }
    report_path.parent.mkdir(parents=True, exist_ok=True)
    report_path.write_text(json.dumps(report, ensure_ascii=False, indent=2), encoding="utf-8")
    print(f"\nüìÅ –û—Ç—á—ë—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {report_path}")


if __name__ == "__main__":
    main()


