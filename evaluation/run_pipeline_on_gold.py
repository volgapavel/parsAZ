"""
evaluation/run_pipeline_on_gold.py

–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞ –¥–ª—è —Å—Ç–∞—Ç–µ–π –∏–∑ gold-–¥–∞—Ç–∞—Å–µ—Ç–∞
–∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏—Ö –≤ evaluation/reports/predictions_on_gold.json.

–ó–∞—á–µ–º:
 - —á—Ç–æ–±—ã —Å—á–∏—Ç–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ –æ–¥–∏–Ω–∞–∫–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ (gold vs predictions)

–ó–∞–ø—É—Å–∫:
    . .venv/bin/activate
    python evaluation/run_pipeline_on_gold.py

–ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —á–∏—Ç–∞–µ—Ç:
 - evaluation/gold/gold_dataset.json
–ü–∏—à–µ—Ç:
 - evaluation/reports/predictions_on_gold.json

–í–∞–∂–Ω–æ:
 - –î–ª—è —Ä–µ–∞–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ NER:
   torch, transformers (–∏ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ spacy)
 - –í –ø—Ä–æ–µ–∫—Ç–µ –µ—Å—Ç—å –¥–≤–∞ –≤–∞—Ä–∏–∞–Ω—Ç–∞ NER:
   1) legacy: entity_extractor_ner_ensemble.NEREnsembleExtractor (–≤—ã–¥–∞—ë—Ç dict entities)
   2) new: model/ner_module.NERModule (–≤—ã–¥–∞—ë—Ç list[dict] —Å –ø–æ–ª—è–º–∏ name/type/...)
"""

from __future__ import annotations

import argparse
import json
import os
import sys
from pathlib import Path
from typing import Any, Dict, List, Optional


def project_root() -> Path:
    return Path(__file__).resolve().parents[1]


def to_serializable(obj: Any) -> Any:
    if hasattr(obj, "to_dict"):
        return obj.to_dict()
    if hasattr(obj, "__dict__") and not isinstance(obj, dict):
        return obj.__dict__
    if isinstance(obj, list):
        return [to_serializable(x) for x in obj]
    if isinstance(obj, dict):
        return {k: to_serializable(v) for k, v in obj.items()}
    return obj


def safe_import(module_name: str, class_name: str):
    try:
        module = __import__(module_name)
        return getattr(module, class_name)()
    except Exception as e:
        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å {module_name}.{class_name}: {e}")
        return None


def load_gold_articles(path: Path) -> List[Dict[str, Any]]:
    data = json.loads(path.read_text(encoding="utf-8"))
    if not isinstance(data, list):
        raise ValueError("gold_dataset.json –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ø–∏—Å–∫–æ–º –æ–±—ä–µ–∫—Ç–æ–≤")
    return data


def ensure_dirs(root: Path) -> None:
    (root / "evaluation" / "reports").mkdir(parents=True, exist_ok=True)


def build_knowledge_graph(entities: Dict[str, Any], relations: List[Any]) -> Dict[str, Any]:
    kg = {"nodes": [], "edges": []}

    for ent in entities.get("all", []) or []:
        if isinstance(ent, dict):
            name = ent.get("name", "")
            etype = ent.get("type") or ent.get("entity_type") or "UNKNOWN"
        else:
            name = getattr(ent, "name", str(ent))
            etype = getattr(ent, "entity_type", getattr(ent, "type", "UNKNOWN"))

        if name:
            kg["nodes"].append({"id": name, "type": etype, "name": name})

    for r in relations or []:
        if hasattr(r, "to_dict"):
            kg["edges"].append(r.to_dict())
        elif isinstance(r, dict):
            kg["edges"].append(r)

    return kg


def normalize_model_entities_to_legacy(entities_list: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    model/ner_module.py –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–ª–æ—Å–∫–∏–π —Å–ø–∏—Å–æ–∫:
      [{name,type,confidence,start,end}, ...]
    –ü—Ä–∏–≤–æ–¥–∏–º –∫ —Ñ–æ—Ä–º–∞—Ç—É evaluation/metrics_evaluator.py:
      {persons:[], organizations:[], locations:[], all:[...]}
    """
    persons = []
    orgs = []
    locs = []
    all_ = []
    for e in entities_list or []:
        if not isinstance(e, dict):
            continue
        et = (e.get("type") or "").lower()
        name = e.get("name")
        if not name:
            continue
        all_.append(e)
        if et == "person":
            persons.append(e)
        elif et == "organization":
            orgs.append(e)
        elif et == "location":
            locs.append(e)
    return {"persons": persons, "organizations": orgs, "locations": locs, "all": all_}


def check_dependencies() -> bool:
    """
    –ú—è–≥–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è torch/transformers.
    –ë–µ–∑ –Ω–∏—Ö NEREnsembleExtractor –Ω–µ –ø–æ–¥–Ω–∏–º–µ—Ç—Å—è.
    """
    try:
        import torch  # noqa: F401
        import transformers  # noqa: F401
        return True
    except Exception:
        return False


def main() -> int:
    root = project_root()
    # –ß—Ç–æ–±—ã –∏–º–ø–æ—Ä—Ç—ã –≤–∏–¥–∞ `import text_preprocessor` —Ä–∞–±–æ—Ç–∞–ª–∏ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ
    # `python evaluation/run_pipeline_on_gold.py`
    if str(root) not in sys.path:
        sys.path.insert(0, str(root))

    # –£ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —Å–µ—Ç–µ–π/–ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ –∑–∞–≥—Ä—É–∑–∫–∞ —á–µ—Ä–µ–∑ Xet –º–æ–∂–µ—Ç ¬´–≤–∏—Å–µ—Ç—å¬ª –Ω–∞ 0%.
    # –û—Ç–∫–ª—é—á–∞–µ–º Xet –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é, —á—Ç–æ–±—ã —Ñ–æ—Ä—Å–∏—Ä–æ–≤–∞—Ç—å –æ–±—ã—á–Ω—É—é HTTP-–∑–∞–≥—Ä—É–∑–∫—É.
    os.environ.setdefault("HF_HUB_DISABLE_XET", "1")
    ensure_dirs(root)

    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--gold",
        default=str(root / "evaluation" / "gold" / "gold_dataset.json"),
        help="–ü—É—Ç—å –∫ gold_dataset.json",
    )
    parser.add_argument(
        "--out",
        default=str(root / "evaluation" / "reports" / "predictions_on_gold.json"),
        help="–ö—É–¥–∞ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è",
    )
    parser.add_argument(
        "--max",
        type=int,
        default=0,
        help="–û–≥—Ä–∞–Ω–∏—á–∏—Ç—å —á–∏—Å–ª–æ —Å—Ç–∞—Ç–µ–π (0 = –≤—Å–µ)",
    )
    parser.add_argument(
        "--engine",
        choices=["ensemble", "model"],
        default="ensemble",
        help="–ö–∞–∫–æ–π NER-–ø–∞–π–ø–ª–∞–π–Ω –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å: ensemble (—Å—Ç–∞—Ä—ã–π) –∏–ª–∏ model (NERModule –∏–∑ model/).",
    )
    parser.add_argument(
        "--model-ner-name",
        default="Davlan/xlm-roberta-large-ner-hrl",
        help="HF model name –¥–ª—è engine=model (model/NERModule).",
    )
    parser.add_argument(
        "--device",
        default="cpu",
        help="–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è engine=model (cpu/cuda). –î–ª—è ensemble –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –≤–Ω—É—Ç—Ä–∏ –º–æ–¥–µ–ª–∏.",
    )
    parser.add_argument(
        "--extract-relationships",
        action="store_true",
        help="–ò–∑–≤–ª–µ–∫–∞—Ç—å –æ—Ç–Ω–æ—à–µ–Ω–∏—è (—Ç—è–∂—ë–ª–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è; –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤—ã–∫–ª—é—á–µ–Ω–æ, —Ç.–∫. –¥–ª—è NER-–º–µ—Ç—Ä–∏–∫ –Ω–µ –Ω—É–∂–Ω–æ).",
    )
    parser.add_argument(
        "--disable-davlan",
        action="store_true",
        help="–ù–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å Davlan (–æ–±—Ö–æ–¥ –ø—Ä–æ–±–ª–µ–º —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —á–µ—Ä–µ–∑ cas-bridge.xethub.hf.co)",
    )
    parser.add_argument(
        "--local-files-only",
        action="store_true",
        help="–ù–µ —Å–∫–∞—á–∏–≤–∞—Ç—å –º–æ–¥–µ–ª–∏ –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞ (—Ç–æ–ª—å–∫–æ –∏–∑ –∫–µ—à–∞).",
    )
    args = parser.parse_args()

    gold_path = Path(args.gold)
    out_path = Path(args.out)
    if not gold_path.is_absolute():
        gold_path = root / gold_path
    if not out_path.is_absolute():
        out_path = root / out_path

    if not gold_path.exists():
        print(f"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω gold dataset: {gold_path}")
        print("   –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ: python evaluation/create_gold_dataset.py")
        return 2

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥—É–ª–µ–π –ø—Ä–æ–µ–∫—Ç–∞
    text_preprocessor = safe_import("text_preprocessor", "TextPreprocessor")
    entity_deduplicator = safe_import("entity_deduplicator", "EntityDeduplicator")
    relation_extractor = safe_import("relationship_extractor_hybrid_pro", "RelationExtractorHybridPro") if args.extract_relationships else None

    ner_extractor = None
    model_ner = None
    if args.engine == "ensemble":
        try:
            from entity_extractor_ner_ensemble import NEREnsembleExtractor
            ner_extractor = NEREnsembleExtractor(
                use_davlan=not args.disable_davlan,
                use_localdoc=True,
                local_files_only=args.local_files_only,
            )
        except Exception as e:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å NEREnsembleExtractor: {e}")
    else:
        try:
            # model/ner_module.py –∏—Å–ø–æ–ª—å–∑—É–µ—Ç relative imports –≤–Ω—É—Ç—Ä–∏ model/, –ø–æ—ç—Ç–æ–º—É –¥–æ–±–∞–≤–∏–º model/ –≤ sys.path
            model_dir = root / "model"
            if str(model_dir) not in sys.path:
                sys.path.insert(0, str(model_dir))
            from ner_module import NERModule  # type: ignore
            model_ner = NERModule(
                model_name=args.model_ner_name,
                device=args.device,
                local_files_only=args.local_files_only,
                use_fast_tokenizer=False,
            )
        except Exception as e:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å model.NERModule: {e}")

    if ner_extractor is None and model_ner is None:
        print("\n‚ùå NER –º–æ–¥—É–ª—å –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª—Å—è.")
        if not check_dependencies():
            print("–ü–æ—Ö–æ–∂–µ, –≤ venv –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ NER.")
            print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –º–∏–Ω–∏–º—É–º:")
            print("  python -m pip install torch transformers")
            print("–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –¥–ª—è —Å–≤—è–∑–µ–π (spaCy —Å–ª–æ–π):")
            print("  python -m pip install spacy && python -m spacy download en_core_web_sm")
        print("\n–ü–æ—Å–ª–µ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ –∑–∞–ø—É—Å–∫ —Å–∫—Ä–∏–ø—Ç–∞.")
        return 3

    gold_articles = load_gold_articles(gold_path)
    if args.max and args.max > 0:
        gold_articles = gold_articles[: args.max]

    results: List[Dict[str, Any]] = []

    print("=" * 70)
    print(f"üöÄ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –Ω–∞ gold-—Å—Ç–∞—Ç—å—è—Ö: {len(gold_articles)}")
    print("=" * 70)

    for idx, a in enumerate(gold_articles, 1):
        article_id = str(a.get("article_id", ""))
        title = str(a.get("title", ""))[:80]
        text = a.get("content", "") or ""

        cleaned_text = text
        if text_preprocessor:
            try:
                cleaned_text = text_preprocessor.preprocess(text) or text
            except Exception:
                cleaned_text = text

        # NER
        if args.engine == "ensemble":
            ner_out = ner_extractor.extract(cleaned_text) or {}
            entities = ner_out.get("entities", {}) if isinstance(ner_out, dict) else {}
        else:
            ents_list = model_ner.extract(cleaned_text) if model_ner else []
            entities = normalize_model_entities_to_legacy(ents_list)

        # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è (–æ–∂–∏–¥–∞–µ—Ç –∫–ª—é—á–∏ persons/organizations)
        if entity_deduplicator and isinstance(entities, dict):
            entities.setdefault("persons", [])
            entities.setdefault("organizations", [])
            try:
                entities = entity_deduplicator.deduplicate_entities(entities) or entities
            except Exception:
                pass

        # –°–≤—è–∑–∏
        relations: List[Any] = []
        if relation_extractor and isinstance(entities, dict) and entities.get("all"):
            try:
                relations = relation_extractor.extract_relationships(cleaned_text, entities) or []
            except Exception:
                relations = []

        kg = build_knowledge_graph(entities if isinstance(entities, dict) else {}, relations)

        results.append(
            {
                "article_id": article_id,
                "source": a.get("source", ""),
                "title": title,
                "entities": to_serializable(entities),
                "knowledge_graph": kg,
                "success": True,
            }
        )

        if idx % 5 == 0 or idx == len(gold_articles):
            print(f"[{idx}/{len(gold_articles)}] ‚úÖ {article_id} {title}")

    out_path.write_text(json.dumps(to_serializable(results), ensure_ascii=False, indent=2), encoding="utf-8")
    print(f"\nüìÅ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {out_path}")
    print("–î–∞–ª—å—à–µ: –∑–∞–ø—É—Å—Ç–∏—Ç–µ –ø–æ–¥—Å—á—ë—Ç –º–µ—Ç—Ä–∏–∫ –∫–æ–º–∞–Ω–¥–æ–π:")
    print("  python evaluation/metrics_evaluator.py")

    return 0


if __name__ == "__main__":
    raise SystemExit(main())


