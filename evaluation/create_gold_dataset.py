"""
evaluation/create_gold_dataset.py

–°–æ–∑–¥–∞—ë—Ç —à–∞–±–ª–æ–Ω gold-–¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è —Ä—É—á–Ω–æ–π —Ä–∞–∑–º–µ—Ç–∫–∏:
- –±–µ—Ä—ë—Ç –ø–æ N —Å—Ç–∞—Ç–µ–π –∏–∑ 01.csv, 02.csv, 03.csv (—ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–ª–∏–Ω–µ + –¥–æ–±–æ—Ä)
- —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç JSON –≤ evaluation/gold/gold_dataset.json

–ó–∞–ø—É—Å–∫:
    python3 evaluation/create_gold_dataset.py --per-source 50 --read-limit 5000 --append
    python3 evaluation/create_gold_dataset.py --per-source 50 --read-limit 5000 --exclude-verified --strict --out evaluation/gold/gold_dataset_50x3_unlabeled.json
"""

from __future__ import annotations

import argparse
import json
import random
import time
from pathlib import Path
from typing import Any, Dict, List, Tuple

import pandas as pd

RANDOM_SEED = 42
random.seed(RANDOM_SEED)


def project_root() -> Path:
    # evaluation/ -> –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –Ω–∞ 1 —É—Ä–æ–≤–µ–Ω—å –≤—ã—à–µ
    return Path(__file__).resolve().parents[1]


def load_csv_articles(csv_file: Path, limit: int = 200) -> List[Dict[str, Any]]:
    """–ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç–∞—Ç–µ–π –∏–∑ CSV (–ø–µ—Ä–≤—ã–µ limit —Å—Ç—Ä–æ–∫)."""
    df = pd.read_csv(csv_file, nrows=limit)
    articles: List[Dict[str, Any]] = []

    for _, row in df.iterrows():
        content = str(row.get("content", "") or "")
        title = str(row.get("title", "") or "")

        article = {
            "id": str(row.get("id", "")),
            "link": str(row.get("link", "") or ""),
            "pub_date": str(row.get("pub_date", "") or ""),
            "title": title,
            "content": content,
        }

        # —Ñ–∏–ª—å—Ç—Ä ¬´–ø—É—Å—Ç—ã—Ö¬ª/—Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏—Ö
        if article["id"] and len(content) >= 200 and len(title) >= 5:
            articles.append(article)

    return articles


def select_diverse_articles(articles: List[Dict[str, Any]], n: int) -> List[Dict[str, Any]]:
    """
    –í—ã–±–æ—Ä —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π: —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ –ø–æ –¥–ª–∏–Ω–µ (–∫–≤–∞–Ω—Ç–∏–ª–∏) + —Å–ª—É—á–∞–π–Ω—ã–π –¥–æ–±–æ—Ä.
    –≠—Ç–æ –ù–ï gold-—Å—Ç—Ä–∞—Ç–µ–≥–∏—è, –Ω–æ –ø–æ–º–æ–≥–∞–µ—Ç –ø–æ–ª—É—á–∏—Ç—å —Ä–∞–∑–Ω—ã–π —Ç–µ–∫—Å—Ç.
    """
    if not articles:
        return []

    sorted_articles = sorted(articles, key=lambda x: len(x["content"]))
    m = len(sorted_articles)

    if n <= 0:
        return []

    # –ò–Ω–¥–µ–∫—Å—ã —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ –ø–æ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–º—É —Å–ø–∏—Å–∫—É
    if m == 1:
        return sorted_articles[:1]
    step = (m - 1) / max(1, (n - 1))
    indices = [min(int(round(i * step)), m - 1) for i in range(n)]

    selected: List[Dict[str, Any]] = []
    seen_ids = set()
    for idx in indices:
        art = sorted_articles[idx]
        if art["id"] in seen_ids:
            continue
        selected.append(art)
        seen_ids.add(art["id"])

    # –µ—Å–ª–∏ –∏–∑-–∑–∞ –¥—É–±–ª–µ–π/–º–∞–ª–æ–≥–æ m –Ω–µ –¥–æ–±—Ä–∞–ª–∏ ‚Äî –¥–æ–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω–æ
    if len(selected) < min(n, m):
        pool = [a for a in sorted_articles if a["id"] not in seen_ids]
        need = min(n, m) - len(selected)
        if pool and need > 0:
            selected.extend(random.sample(pool, k=min(need, len(pool))))

    return selected[:n]


def create_gold_template(article: Dict[str, Any], source: str) -> Dict[str, Any]:
    """–®–∞–±–ª–æ–Ω –æ–¥–Ω–æ–π —Å—Ç–∞—Ç—å–∏ –¥–ª—è —Ä—É—á–Ω–æ–π —Ä–∞–∑–º–µ—Ç–∫–∏."""
    return {
        "article_id": str(article["id"]),
        "source": source,
        "link": article.get("link", ""),
        "pub_date": article.get("pub_date", ""),
        "title": article.get("title", ""),
        "content": (article.get("content", "") or "")[:4000],  # —á—Ç–æ–±—ã —É–¥–æ–±–Ω–µ–µ —Ä–∞–∑–º–µ—á–∞—Ç—å
        "gold_entities": {
            "persons": [],
            "organizations": [],
            "locations": [],
            "positions": [],
            "dates": [],
        },
        "manually_verified": False,
        "annotator_notes": "",
    }


def ensure_dirs(base: Path) -> None:
    (base / "evaluation" / "gold").mkdir(parents=True, exist_ok=True)
    (base / "evaluation" / "reports").mkdir(parents=True, exist_ok=True)


def load_existing_gold(path: Path) -> List[Dict[str, Any]]:
    if not path.exists():
        return []
    return json.loads(path.read_text(encoding="utf-8"))


def key_for(item: Dict[str, Any]) -> Tuple[str, str]:
    # –£–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å –≤ —Ä–∞–º–∫–∞—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–∞
    return (str(item.get("source", "")).strip(), str(item.get("article_id", "")).strip())


def main() -> None:
    root = project_root()
    ensure_dirs(root)

    parser = argparse.ArgumentParser()
    parser.add_argument("--per-source", type=int, default=10, help="–°–∫–æ–ª—å–∫–æ —Å—Ç–∞—Ç–µ–π –±—Ä–∞—Ç—å –Ω–∞ –∫–∞–∂–¥—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫")
    parser.add_argument("--read-limit", type=int, default=200, help="–°–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫ —á–∏—Ç–∞—Ç—å –∏–∑ –∫–∞–∂–¥–æ–≥–æ CSV (–ø–µ—Ä–≤—ã–µ N —Å—Ç—Ä–æ–∫)")
    parser.add_argument("--append", action="store_true", help="–†–∞—Å—à–∏—Ä—è—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π gold_dataset.json (–Ω–µ –ø–µ—Ä–µ–∑–∞—Ç–∏—Ä–∞—Ç—å)")
    parser.add_argument(
        "--exclude-verified",
        action="store_true",
        help="–ò—Å–∫–ª—é—á–∞—Ç—å –∏–∑ –≤—ã–±–æ—Ä–∫–∏ —Å—Ç–∞—Ç—å–∏, –∫–æ—Ç–æ—Ä—ã–µ —É–∂–µ –≤—Ä—É—á–Ω—É—é —Ä–∞–∑–º–µ—á–µ–Ω—ã (manually_verified=true) –≤ —Ç–µ–∫—É—â–µ–º gold_dataset.json",
    )
    parser.add_argument(
        "--strict",
        action="store_true",
        help="–¢—Ä–µ–±–æ–≤–∞—Ç—å —Å—Ç—Ä–æ–≥–æ per-source —Å—Ç–∞—Ç–µ–π –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫ (–µ—Å–ª–∏ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç ‚Äî –æ—à–∏–±–∫–∞).",
    )
    parser.add_argument(
        "--out",
        type=str,
        default="",
        help="–ü—É—Ç—å –¥–ª—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é evaluation/gold/gold_dataset.json).",
    )
    args = parser.parse_args()

    sources = {
        "report.az": root / "01.csv",
        "azerbaijan.az": root / "02.csv",
        "trend.az": root / "03.csv",
    }

    default_out = root / "evaluation" / "gold" / "gold_dataset.json"
    out_file = Path(args.out) if args.out else default_out
    if not out_file.is_absolute():
        out_file = root / out_file

    # –¢–µ–∫—É—â–∏–π gold (–∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞–∫ –∏—Å—Ç–æ—á–Ω–∏–∫ –∏—Å–∫–ª—é—á–µ–Ω–∏–π –∏/–∏–ª–∏ –∫–∞–∫ –±–∞–∑–∞ –¥–ª—è append)
    current_gold: List[Dict[str, Any]] = load_existing_gold(default_out)
    verified_exclude = {
        key_for(x)
        for x in current_gold
        if isinstance(x, dict) and x.get("manually_verified") is True
    }

    existing: List[Dict[str, Any]] = load_existing_gold(out_file) if (args.append and out_file.exists()) else []
    existing_map = {key_for(x): x for x in existing if isinstance(x, dict)}

    gold_dataset: List[Dict[str, Any]] = list(existing_map.values())

    print("=" * 70)
    target_total = args.per_source * len(sources)
    mode = "append" if args.append else "overwrite"
    print(f"üîß –°–æ–∑–¥–∞–Ω–∏–µ/—Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ gold dataset ({mode})")
    print(f"   per-source={args.per_source} | read-limit={args.read_limit} | target~{target_total}")
    if args.exclude_verified:
        print(f"   exclude_verified: {len(verified_exclude)} articles")
    if args.strict:
        print("   strict: enabled")
    if out_file != default_out:
        print(f"   out: {out_file.relative_to(root) if str(out_file).startswith(str(root)) else out_file}")
    print("=" * 70)

    for source_name, csv_path in sources.items():
        if not csv_path.exists():
            print(f"‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω —Ñ–∞–π–ª: {csv_path}")
            continue

        print(f"\nüì∞ {source_name}: –∑–∞–≥—Ä—É–∑–∫–∞ {csv_path.name} ...")
        articles = load_csv_articles(csv_path, limit=args.read_limit)
        print(f"   –ó–∞–≥—Ä—É–∂–µ–Ω–æ (–ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞): {len(articles)}")

        # –ò—Å–∫–ª—é—á–µ–Ω–∏—è: —É–∂–µ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –≤ –≤—ã—Ö–æ–¥–Ω–æ–º —Ñ–∞–π–ª–µ (append) + –≤—Ä—É—á–Ω—É—é —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–µ (–µ—Å–ª–∏ exclude-verified)
        excluded_keys = set(existing_map.keys())
        if args.exclude_verified:
            excluded_keys |= {k for k in verified_exclude if k[0] == source_name}

        # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ —Ñ–∏–ª—å—Ç—Ä—É–µ–º, —á—Ç–æ–±—ã —Å—Ç—Ä–æ–≥–æ –¥–æ–±—Ä–∞—Ç—å N
        candidates = [a for a in articles if (source_name, str(a["id"])) not in excluded_keys]
        if len(candidates) < args.per_source and args.strict:
            raise SystemExit(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–ª—è {source_name}: –Ω—É–∂–Ω–æ {args.per_source}, –¥–æ—Å—Ç—É–ø–Ω–æ {len(candidates)}. "
                f"–£–≤–µ–ª–∏—á—å—Ç–µ --read-limit."
            )

        selected = select_diverse_articles(candidates, n=min(args.per_source, len(candidates)))
        # –ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π –¥–æ–±–æ—Ä —Å–ª—É—á–∞–π–Ω–æ, –µ—Å–ª–∏ –∫–≤–∞–Ω—Ç–∏–ª—å–Ω—ã–π –æ—Ç–±–æ—Ä –Ω–µ –¥–∞–ª N –∏–∑-–∑–∞ –¥—É–±–ª–µ–π
        if len(selected) < min(args.per_source, len(candidates)):
            seen = {str(x['id']) for x in selected}
            pool = [a for a in candidates if str(a['id']) not in seen]
            need = min(args.per_source, len(candidates)) - len(selected)
            if need > 0 and pool:
                selected.extend(random.sample(pool, k=min(need, len(pool))))

        # –í strict —Ä–µ–∂–∏–º–µ –¥–æ–±–∏–≤–∞–µ–º –¥–æ —Ä–æ–≤–Ω–æ per-source
        if args.strict and len(selected) != args.per_source:
            raise SystemExit(
                f"‚ùå –î–ª—è {source_name} –ø–æ–ª—É—á–∏–ª–æ—Å—å {len(selected)} –≤–º–µ—Å—Ç–æ {args.per_source}. "
                f"–£–≤–µ–ª–∏—á—å—Ç–µ --read-limit."
            )

        print(f"   –í—ã–±—Ä–∞–Ω–æ: {len(selected)} (–∏—Å–∫–ª—é—á–µ–Ω–æ —Ä–∞–Ω–µ–µ/verified: {len(articles) - len(candidates)})")

        for article in selected:
            gold_dataset.append(create_gold_template(article, source_name))

    # backup (–µ—Å–ª–∏ —Ä–∞—Å—à–∏—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π)
    if args.append and out_file.exists():
        ts = time.strftime("%Y%m%d-%H%M%S")
        backup = out_file.with_suffix(f".bak-{ts}.json")
        backup.write_text(out_file.read_text(encoding="utf-8"), encoding="utf-8")
        print(f"\nüß∑ –ë—ç–∫–∞–ø —Å—Ç–∞—Ä–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞: {backup.name}")

    out_file.write_text(json.dumps(gold_dataset, ensure_ascii=False, indent=2), encoding="utf-8")

    print(f"\n‚úÖ –ì–æ—Ç–æ–≤–æ. –°—Ç–∞—Ç–µ–π –≤ —à–∞–±–ª–æ–Ω–µ: {len(gold_dataset)}")
    print(f"üìÅ –§–∞–π–ª: {out_file}")
    print("\n–î–∞–ª—å—à–µ: –æ—Ç–∫—Ä–æ–π—Ç–µ JSON, –∑–∞–ø–æ–ª–Ω–∏—Ç–µ gold_entities –∏ –ø–æ—Å—Ç–∞–≤—å—Ç–µ manually_verified=true.")


if __name__ == "__main__":
    main()


